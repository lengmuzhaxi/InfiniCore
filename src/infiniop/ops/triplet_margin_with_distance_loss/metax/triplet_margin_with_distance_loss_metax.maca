#include "triplet_margin_with_distance_loss_metax.h"
#include "../../../devices/metax/metax_common.h"
#include "../../../devices/metax/metax_handle.h"
#include <mcr/mc_runtime.h>
#include <maca_fp16.h>
#include <maca_bfloat16.h>
#include <cmath>
#include <limits>
#include <cstdint>
#include <algorithm>

namespace op::triplet_margin_with_distance_loss::metax {

// ==================================================================
// Device Helpers: 类型转换与归约
// ==================================================================

__device__ __forceinline__ float to_float(float val) { return val; }
__device__ __forceinline__ float to_float(double val) { return static_cast<float>(val); }
__device__ __forceinline__ float to_float(__half val) { return __half2float(val); }
__device__ __forceinline__ float to_float(__maca_bfloat16 val) { return __bfloat162float(val); }

template <typename T>
__device__ __forceinline__ T warp_reduce_sum(T val) {
    for (int offset = 32 / 2; offset > 0; offset /= 2) {
        val += __shfl_down_sync(0xffffffff, val, offset);
    }
    return val;
}

template <typename T>
__device__ __forceinline__ T block_reduce_sum(T val) {
    static __shared__ float shared[32]; 
    int lane = threadIdx.x % 32;
    int wid = threadIdx.x / 32;

    val = warp_reduce_sum(val);

    if (lane == 0) shared[wid] = val;
    __syncthreads();

    val = (threadIdx.x < blockDim.x / 32) ? shared[lane] : 0.0f;
    
    if (wid == 0) val = warp_reduce_sum(val);
    
    return val;
}

// ==================================================================
// Kernels
// ==================================================================

template <typename T>
__global__ void triplet_margin_loss_kernel(
    T * __restrict__ output,        // [BatchSize] (仅当 Reduction=None 时使用)
    float * __restrict__ reduction_buffer, // [1] FP32 Accumulator (仅当 Reduction!=None 时使用)
    const T * __restrict__ anchor,  
    const T * __restrict__ positive,
    const T * __restrict__ negative,
    size_t feature_dim,
    float margin,
    int swap,       
    int reduction,  // 0: None, 1: Mean, 2: Sum
    size_t batch_size
) {
    size_t batch_idx = blockIdx.x;
    if (batch_idx >= batch_size) return;

    size_t tid = threadIdx.x;
    size_t stride = blockDim.x;

    size_t offset_base = batch_idx * feature_dim;

    float sum_sq_ap = 0.0f;
    float sum_sq_an = 0.0f;
    float sum_sq_pn = 0.0f; 

    for (size_t i = tid; i < feature_dim; i += stride) {
        size_t idx = offset_base + i;
        float a = to_float(anchor[idx]);
        float p = to_float(positive[idx]);
        float n = to_float(negative[idx]);

        float diff_ap = a - p;
        sum_sq_ap += diff_ap * diff_ap;

        float diff_an = a - n;
        sum_sq_an += diff_an * diff_an;

        if (swap) {
            float diff_pn = p - n;
            sum_sq_pn += diff_pn * diff_pn;
        }
    }

    float dist_sq_ap = block_reduce_sum(sum_sq_ap);
    float dist_sq_an = block_reduce_sum(sum_sq_an);
    float dist_sq_pn = 0.0f;
    if (swap) {
        dist_sq_pn = block_reduce_sum(sum_sq_pn);
    }

    if (tid == 0) {
        float eps = 1e-6f;
        float dist_ap = sqrtf(dist_sq_ap + eps);
        float dist_an = sqrtf(dist_sq_an + eps);

        if (swap) {
            float dist_pn = sqrtf(dist_sq_pn + eps);
            if (dist_pn < dist_an) {
                dist_an = dist_pn;
            }
        }

        float loss = fmaxf(dist_ap - dist_an + margin, 0.0f);

        if (reduction == 0) { // None
            output[batch_idx] = static_cast<T>(loss);
        } else { // Sum or Mean
            atomicAdd(reduction_buffer, loss);
        }
    }
}

template <typename T>
__global__ void cast_and_scale_kernel(T *output, const float *reduction_buffer, size_t batch_size, int reduction) {
    if (threadIdx.x == 0) {
        float val = reduction_buffer[0];
        
        // 如果是 Mean 模式，进行除法
        if (reduction == 1) { 
            val /= static_cast<float>(batch_size);
        }
        
        output[0] = static_cast<T>(val);
    }
}

// ==================================================================
// Host Implementation
// ==================================================================

struct Descriptor::Opaque {
    size_t batch_size;
    size_t feature_dim;
};

template <typename T>
void launch_kernel(
    void *output, 
    void *workspace,      // Workspace pointer (float*)
    const void *anchor, 
    const void *positive, 
    const void *negative, 
    const TripletMarginWithDistanceLossInfo& info,
    size_t batch_size, 
    size_t feature_dim,
    void *stream) {

    auto out_ptr = reinterpret_cast<T *>(output);
    auto ws_ptr = reinterpret_cast<float *>(workspace); // FP32 Workspace
    auto anchor_ptr = reinterpret_cast<const T *>(anchor);
    auto pos_ptr = reinterpret_cast<const T *>(positive);
    auto neg_ptr = reinterpret_cast<const T *>(negative);
    
    auto mc_stream = reinterpret_cast<mcStream_t>(stream);
    
    float margin = info.margin();
    int swap = info.swap();
    int reduction = info.reduction(); // 0:None, 1:Mean, 2:Sum

    size_t grid_size = batch_size;
    
    unsigned int threads_per_block = 256;
    if (feature_dim < 256) threads_per_block = 128;
    if (feature_dim < 128) threads_per_block = 64;
    if (feature_dim < 64)  threads_per_block = 32;

    // 1. 初始化 Accumulator
    if (reduction != 0) {
        mcMemsetAsync(ws_ptr, 0, sizeof(float), mc_stream);
    }

    triplet_margin_loss_kernel<T>
        <<<grid_size, threads_per_block, 0, mc_stream>>>(
            out_ptr, 
            ws_ptr, // 传递 workspace
            anchor_ptr, 
            pos_ptr, 
            neg_ptr, 
            feature_dim, 
            margin, 
            swap,
            reduction,
            batch_size
        );

    // 3. 后处理: Cast & Mean
    if (reduction != 0) {
        cast_and_scale_kernel<T>
            <<<1, 1, 0, mc_stream>>>(
                out_ptr, 
                ws_ptr, 
                batch_size,
                reduction
            );
    }
}

Descriptor::~Descriptor() { 
    if (_opaque) delete _opaque; 
}

infiniStatus_t Descriptor::create(
    infiniopHandle_t handle_, Descriptor **desc_ptr,
    infiniopTensorDescriptor_t output_desc, 
    infiniopTensorDescriptor_t anchor_desc, 
    infiniopTensorDescriptor_t positive_desc, 
    infiniopTensorDescriptor_t negative_desc,
    float margin,
    int swap,
    int reduction) {

    auto handle = reinterpret_cast<device::metax::Handle *>(handle_);

    auto info_result = TripletMarginWithDistanceLossInfo::create(
        output_desc, anchor_desc, positive_desc, negative_desc, margin, swap, reduction);
    if (!info_result) return info_result.status();

    int ndim = anchor_desc->ndim();
    size_t feature_dim = (ndim > 0) ? anchor_desc->shape()[ndim - 1] : 1;
    size_t total_elements = info_result->num_elements();
    size_t batch_size = total_elements / feature_dim;

    auto opaque = new Opaque();
    opaque->batch_size = batch_size;
    opaque->feature_dim = feature_dim;
    size_t workspace_size = (reduction != 0) ? sizeof(float) : 0;

    *desc_ptr = new Descriptor(opaque, info_result.take(), workspace_size, handle->device, handle->device_id);
    return INFINI_STATUS_SUCCESS;
}

infiniStatus_t Descriptor::calculate(
    void *workspace, 
    size_t workspace_size, 
    void *output, 
    const void *anchor, 
    const void *positive, 
    const void *negative, 
    void *stream) const {

    auto dtype = _info.dtype();
    size_t batch_size = _opaque->batch_size;
    size_t feature_dim = _opaque->feature_dim;

    switch (dtype) {
    case INFINI_DTYPE_F16:
        launch_kernel<__half>(output, workspace, anchor, positive, negative, _info, batch_size, feature_dim, stream);
        break;
    case INFINI_DTYPE_BF16:
        launch_kernel<__maca_bfloat16>(output, workspace, anchor, positive, negative, _info, batch_size, feature_dim, stream);
        break;
    case INFINI_DTYPE_F32:
        launch_kernel<float>(output, workspace, anchor, positive, negative, _info, batch_size, feature_dim, stream);
        break;
    case INFINI_DTYPE_F64:
        launch_kernel<double>(output, workspace, anchor, positive, negative, _info, batch_size, feature_dim, stream);
        break;
    default:
        return INFINI_STATUS_BAD_TENSOR_DTYPE;
    }

    return INFINI_STATUS_SUCCESS;
}

} // namespace op::triplet_margin_with_distance_loss::metax