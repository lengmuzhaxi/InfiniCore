#include "logcumsumexp_metax.h" 
#include "../../../devices/metax/metax_common.h"
#include "../../../devices/metax/metax_handle.h"
#include <mcr/mc_runtime.h>
#include <cstdint>
#include <cmath>
#include <limits>
#include <maca_fp16.h>
#include <maca_bfloat16.h>


namespace op::logcumsumexp::metax {


struct LSEState {
    float m;   // running max
    float s;   // sum(exp(x - m))

    // 数学单位元：log(0) = -inf
    __device__ __forceinline__ static LSEState identity() {
        return { -INFINITY, 0.0f };
    }

    // prefix 更新逻辑
    __device__ __forceinline__ void update(float v) {
        if (m == -INFINITY) {
            // 第一个有效值
            m = v;
            s = 1.0f;
        } else if (v > m) {
            // 新的 max 出现，需要缩放之前的 sum
            // s_new = s_old * exp(old_m - new_v) + 1
            s = s * expf(m - v) + 1.0f;
            m = v;
        } else {
            // 累加项
            s += expf(v - m);
        }
    }

    // 计算当前的 log-sum-exp 值: m + log(s)
    __device__ __forceinline__ float value() const {
        return (s == 0.0f) ? -INFINITY : (m + logf(s));
    }
};


template <typename T>
__global__ void logcumsumexp_kernel(
    T* __restrict__ y,
    const T* __restrict__ x,

    size_t outer_size,
    size_t axis_size,
    size_t inner_size,

    size_t x_axis_stride,
    size_t x_inner_stride,
    size_t x_outer_stride,

    size_t y_axis_stride,
    size_t y_inner_stride,
    size_t y_outer_stride,

    bool exclusive,
    bool reverse
) {
    size_t tid = blockIdx.x * blockDim.x + threadIdx.x;
    size_t num_vec = outer_size * inner_size;
    if (tid >= num_vec) return;

    // 计算当前的 outer (o) 和 inner (i) 索引
    size_t o = tid / inner_size;
    size_t i = tid % inner_size;

    // 计算 Base Offset
    size_t x_base = o * x_outer_stride + i * x_inner_stride;
    size_t y_base = o * y_outer_stride + i * y_inner_stride;

    LSEState state = LSEState::identity();

    // 沿 Axis 维度循环
    for (size_t k = 0; k < axis_size; ++k) {
        // 处理 reverse (从后向前累加)
        size_t kk = reverse ? (axis_size - 1 - k) : k;

        size_t x_off = x_base + kk * x_axis_stride;
        size_t y_off = y_base + kk * y_axis_stride;

        // 统一转为 float 计算
        float v = static_cast<float>(x[x_off]);

        if (exclusive) {
            // Exclusive: 先写入当前状态，再更新
            // y[0] = log(0) = -inf
            y[y_off] = static_cast<T>(state.value());
            state.update(v);
        } else {
            // Inclusive: 先更新状态，再写入
            // y[0] = x[0]
            state.update(v);
            y[y_off] = static_cast<T>(state.value());
        }
    }
}


template <typename T>
void launch_kernel(
    void* y,
    const void* x,
    const LogCumSumExpInfo& info,
    void* stream) {

    auto x_ptr = reinterpret_cast<const T*>(x);
    auto y_ptr = reinterpret_cast<T*>(y);
    auto mc_stream = reinterpret_cast<mcStream_t>(stream);

    size_t outer = info.outer_size();
    size_t axis  = info.axis_size();
    size_t inner = info.inner_size();

    size_t total = outer * inner;
    constexpr size_t block = 256;
    size_t grid = (total + block - 1) / block;

    logcumsumexp_kernel<T>
        <<<grid, block, 0, mc_stream>>>(
            y_ptr,
            x_ptr,
            outer,
            axis,
            inner,

            info._x_axis_stride,
            info._x_inner_stride,
            info._x_outer_stride,

            info._y_axis_stride,
            info._y_inner_stride,
            info._y_outer_stride,

            info.exclusive(),
            info.reverse()
        );
}

struct Descriptor::Opaque {};

Descriptor::~Descriptor() {
    if (_opaque) delete _opaque;
}

infiniStatus_t Descriptor::create(
    infiniopHandle_t handle_,
    Descriptor** desc_ptr,
    infiniopTensorDescriptor_t y_desc,
    infiniopTensorDescriptor_t x_desc,
    int axis,
    int exclusive,
    int reverse) {

    auto handle = reinterpret_cast<device::metax::Handle *>(handle_);
    
    auto info_result =
        LogCumSumExpInfo::create(y_desc, x_desc, axis, exclusive, reverse);
    if (!info_result) return info_result.status();

    *desc_ptr = new Descriptor(
        new Opaque(),
        info_result.take(),
        /*workspace*/ 0,
        handle->device,
        handle->device_id
    );

    return INFINI_STATUS_SUCCESS;
}

infiniStatus_t Descriptor::calculate(
    void* workspace,
    size_t workspace_size,
    void* y,
    const void* x,
    void* stream) const {

    switch (_info.dtype()) {
    case INFINI_DTYPE_F16:
        launch_kernel<__half>(y, x, _info, stream);
        break;
    case INFINI_DTYPE_BF16:
#if defined(__MACA__) || defined(__MACACC__)
        launch_kernel<__maca_bfloat16>(y, x, _info, stream);
#endif
        break;
    case INFINI_DTYPE_F32:
        launch_kernel<float>(y, x, _info, stream);
        break;
    case INFINI_DTYPE_F64:
        launch_kernel<double>(y, x, _info, stream);
        break;
    default:
        return INFINI_STATUS_BAD_TENSOR_DTYPE;
    }

    return INFINI_STATUS_SUCCESS;
}

} // namespace op::logcumsumexp::metax